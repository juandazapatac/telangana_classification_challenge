{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "This notebook searchs to use machine learning techniques to model the studied data in the exploratory_analysis.ipynb notebook. First we import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the data collected from the satellite images (See the satellite processing folder) is added to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Train.csv')\n",
    "df_encoded = pd.read_csv('../data/train_encoded.csv')\n",
    "df = pd.concat([df,df_encoded.ndvi,df_encoded.evi,df_encoded.ndwi,df_encoded.gndvi,df_encoded.savi,df_encoded.msavi],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About one thousand farms don't satellite data associted so all they have for the new data are missing values. These records are dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a short multivariate analysis to see what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ndvi</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ndwi</th>\n",
       "      <th colspan=\"2\" halign=\"left\">gndvi</th>\n",
       "      <th colspan=\"2\" halign=\"left\">savi</th>\n",
       "      <th colspan=\"2\" halign=\"left\">msavi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diseased</th>\n",
       "      <td>0.568699</td>\n",
       "      <td>1.460792</td>\n",
       "      <td>10.042921</td>\n",
       "      <td>2.677730</td>\n",
       "      <td>0.254835</td>\n",
       "      <td>0.694027</td>\n",
       "      <td>0.839677</td>\n",
       "      <td>2.176318</td>\n",
       "      <td>3878.101041</td>\n",
       "      <td>1390.030283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthy</th>\n",
       "      <td>0.682831</td>\n",
       "      <td>1.637722</td>\n",
       "      <td>10.215223</td>\n",
       "      <td>2.771421</td>\n",
       "      <td>0.295578</td>\n",
       "      <td>0.899111</td>\n",
       "      <td>1.015285</td>\n",
       "      <td>2.448178</td>\n",
       "      <td>3845.658390</td>\n",
       "      <td>1505.893835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pests</th>\n",
       "      <td>0.725410</td>\n",
       "      <td>1.800500</td>\n",
       "      <td>10.218539</td>\n",
       "      <td>2.646600</td>\n",
       "      <td>0.257164</td>\n",
       "      <td>0.553859</td>\n",
       "      <td>1.085837</td>\n",
       "      <td>2.700968</td>\n",
       "      <td>3879.532629</td>\n",
       "      <td>1503.934969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stressed</th>\n",
       "      <td>0.912816</td>\n",
       "      <td>2.261620</td>\n",
       "      <td>10.440244</td>\n",
       "      <td>2.919329</td>\n",
       "      <td>0.362572</td>\n",
       "      <td>1.271307</td>\n",
       "      <td>1.345018</td>\n",
       "      <td>3.316586</td>\n",
       "      <td>3763.602500</td>\n",
       "      <td>1556.208114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ndvi                 ndwi               gndvi            \\\n",
       "              mean       std       mean       std      mean       std   \n",
       "category                                                                \n",
       "Diseased  0.568699  1.460792  10.042921  2.677730  0.254835  0.694027   \n",
       "Healthy   0.682831  1.637722  10.215223  2.771421  0.295578  0.899111   \n",
       "Pests     0.725410  1.800500  10.218539  2.646600  0.257164  0.553859   \n",
       "Stressed  0.912816  2.261620  10.440244  2.919329  0.362572  1.271307   \n",
       "\n",
       "              savi                  msavi               \n",
       "              mean       std         mean          std  \n",
       "category                                                \n",
       "Diseased  0.839677  2.176318  3878.101041  1390.030283  \n",
       "Healthy   1.015285  2.448178  3845.658390  1505.893835  \n",
       "Pests     1.085837  2.700968  3879.532629  1503.934969  \n",
       "Stressed  1.345018  3.316586  3763.602500  1556.208114  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_satellite = pd.concat([df.ndvi,df.ndwi,df.gndvi,df.savi,df.msavi,df.category],axis=1)\n",
    "df_satellite_gb = df_satellite.groupby('category')\n",
    "df_satellite_gb.agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the dataset is manipulated in order to keep only those features that may be useful for the intended purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next features are removed from the dataset:\n",
    "- FarmID\n",
    "- State\n",
    "- District\n",
    "- Sub-District\n",
    "- HDate\n",
    "- CNext\n",
    "- ExpYield\n",
    "- geometry\n",
    "- CHeight\n",
    "- evi (Problematic feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['FarmID','State','District','Sub-District','HDate','CNext','ExpYield','geometry','CHeight','evi'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SDate is manipulated to keep only the month data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMonth'] = df['SDate'].map(lambda x:x[-7:-5])\n",
    "df.drop(columns='SDate',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category column is converted to numerical through a fixed encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_encoding = {'Healthy':0,\n",
    "                     'Diseased':1,\n",
    "                     'Pests':2,\n",
    "                     'Stressed':3}\n",
    "\n",
    "df['y'] = df.category.map(category_encoding)\n",
    "df.drop(columns=['category'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical variables are converted to numerical through the label-enconding technique. This is chosen for simplicity but it is important to take into account that this is better suited for ordinal variables which is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder2 = LabelEncoder()\n",
    "label_encoder3 = LabelEncoder()\n",
    "label_encoder4 = LabelEncoder()\n",
    "label_encoder5 = LabelEncoder()\n",
    "label_encoder6 = LabelEncoder()\n",
    "df['crop'] = label_encoder1.fit_transform(df.Crop.values)\n",
    "df['clast'] = label_encoder2.fit_transform(df.CLast.values)\n",
    "df['ctransp'] = label_encoder3.fit_transform(df.CTransp.values)\n",
    "df['irritype'] = label_encoder4.fit_transform(df.IrriType.values)\n",
    "df['irrisource'] = label_encoder5.fit_transform(df.IrriSource.values)\n",
    "df['season'] = label_encoder6.fit_transform(df.Season.values)\n",
    "df.drop(columns=['Crop','CLast','CTransp', 'IrriType','IrriSource','Season'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, numerical variables are scaled as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "scaler3 = StandardScaler()\n",
    "scaler4 = StandardScaler()\n",
    "scaler5 = StandardScaler()\n",
    "scaler6 = StandardScaler()\n",
    "scaler7 = StandardScaler()\n",
    "\n",
    "df['crop_covered_area'] = scaler1.fit_transform(pd.DataFrame(df.CropCoveredArea))\n",
    "df['water_cov'] = scaler2.fit_transform(pd.DataFrame(df.WaterCov))\n",
    "df['ndvi'] = scaler3.fit_transform(pd.DataFrame(df.ndvi))\n",
    "df['ndwi'] = scaler4.fit_transform(pd.DataFrame(df.ndwi))\n",
    "df['gndvi'] = scaler5.fit_transform(pd.DataFrame(df.gndvi))\n",
    "df['savi'] = scaler6.fit_transform(pd.DataFrame(df.savi))\n",
    "df['msavi'] = scaler7.fit_transform(pd.DataFrame(df.msavi))\n",
    "\n",
    "\n",
    "df.drop(columns=['CropCoveredArea','WaterCov'],inplace=True)\n",
    "df.sort_index(axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step attemps to prepare the provided test data so that it can be evaluated by the models to be built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/Test.csv')\n",
    "#Satellite data\n",
    "df_test_encoded = pd.read_csv('../data/test_encoded.csv')\n",
    "df_test = pd.concat([df_test,df_test_encoded.ndvi,df_test_encoded.evi,df_test_encoded.ndwi,df_test_encoded.gndvi,\n",
    "                   df_test_encoded.savi,df_test_encoded.msavi],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records in the test data with missing values cannot be just dropped as it was done for the training data as they are must be there so that submissions to the platform are valid.\n",
    "\n",
    "So another approach for missing values must me performed. Missing values are fill with the variable's mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [df_test.ndvi,df_test.evi,df_test.ndwi,df_test.gndvi, df_test.savi,df_test.msavi]:\n",
    "    column.fillna(column.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the rest of required transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used columns\n",
    "df_test.drop(columns = ['FarmID','State','District','Sub-District','HDate','CNext',\n",
    "                      'ExpYield','geometry','CHeight','evi'],inplace=True)\n",
    "# Date to Month\n",
    "df_test['SMonth'] = df_test['SDate'].map(lambda x:x[-7:-5])\n",
    "df_test.drop(columns = 'SDate',inplace = True)\n",
    "# Label Encoding\n",
    "df_test['crop'] = label_encoder1.transform(df_test.Crop.values)\n",
    "df_test['clast'] = label_encoder2.transform(df_test.CLast.values)\n",
    "df_test['ctransp'] = label_encoder3.transform(df_test.CTransp.values)\n",
    "df_test['irritype'] = label_encoder4.transform(df_test.IrriType.values)\n",
    "df_test['irrisource'] = label_encoder5.transform(df_test.IrriSource.values)\n",
    "df_test['season'] = label_encoder6.transform(df_test.Season.values)\n",
    "df_test.drop(columns = ['Crop','CLast','CTransp', 'IrriType','IrriSource','Season'],inplace=True)\n",
    "# Scaling\n",
    "df_test['crop_covered_area'] = scaler1.transform(pd.DataFrame(df_test.CropCoveredArea))\n",
    "df_test['water_cov'] = scaler2.transform(pd.DataFrame(df_test.WaterCov))\n",
    "df_test['ndvi'] = scaler3.fit_transform(pd.DataFrame(df_test.ndvi))\n",
    "df_test['ndwi'] = scaler4.fit_transform(pd.DataFrame(df_test.ndwi))\n",
    "df_test['gndvi'] = scaler5.fit_transform(pd.DataFrame(df_test.gndvi))\n",
    "df_test['savi'] = scaler6.fit_transform(pd.DataFrame(df_test.savi))\n",
    "df_test['msavi'] = scaler7.fit_transform(pd.DataFrame(df_test.msavi))\n",
    "df_test.drop(columns = ['CropCoveredArea','WaterCov'],inplace=True)\n",
    "# Sorting columns\n",
    "df_test.sort_index(axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=df.y\n",
    "X_train=df.drop(columns='y')\n",
    "X_test=df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the *curse of dimensionality* only three variables are used with this algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted average f1-score for 1 neighbors is 0.69600555973801\n",
      "The weighted average f1-score for 2 neighbors is 0.7326263204638507\n",
      "The weighted average f1-score for 3 neighbors is 0.7378557350508214\n",
      "The weighted average f1-score for 4 neighbors is 0.7315497662425016\n",
      "The weighted average f1-score for 5 neighbors is 0.7304993757802747\n"
     ]
    }
   ],
   "source": [
    "# Only the ndvi, savi and SMonth variables are kept\n",
    "X_train_knn = pd.concat([X_train.ndvi,X_train.savi,X_train.water_cov],axis=1)\n",
    "\n",
    "\n",
    "# For this case, we will divide the original training data\n",
    "X_train_knn,X_test_knn,y_train_knn,y_test_knn = train_test_split(X_train_knn,y_train,test_size=0.2,\n",
    "                                                               random_state=42, shuffle=True)\n",
    "\n",
    "for n in range(1,6):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train_knn,y_train_knn)\n",
    "    y_pred_knn = knn.predict(X_test_knn)\n",
    "    f1_score_knn = f1_score(y_test_knn,y_pred_knn,average=\"weighted\")\n",
    "    print('The weighted average f1-score for',n,'neighbors is',f1_score_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last, it is possible to observe that the best number for N is 3.\n",
    "(Different variable combinations were also tested despite not being shown here).\n",
    "\n",
    "Now we train an algorithm without splitting the training data, and we test it using the actual test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_knn = pd.concat([X_train.ndvi,X_train.savi,X_train.water_cov],axis=1)\n",
    "X_test_knn = pd.concat([X_test.ndvi,X_test.savi,X_test.water_cov],axis=1)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=n)\n",
    "knn.fit(X_train_knn,y_train)\n",
    "y_pred_knn = knn.predict(X_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(submission_number,y_pred):\n",
    "    '''\n",
    "    Creates a file ready to submit to the ZINDI platform\n",
    "    '''\n",
    "    submission = pd.read_csv('../data/Test.csv') # Gets the original test file which has the Farm IDs\n",
    "    decoded_categories = []\n",
    "    for i in y_pred:\n",
    "        if i==0: decoded_categories.append('Healthy')\n",
    "        elif i==1: decoded_categories.append('Diseased')\n",
    "        elif i==2: decoded_categories.append('Pests')\n",
    "        elif i==3: decoded_categories.append('Stressed')\n",
    "    submission = pd.concat([submission.FarmID,pd.Series(decoded_categories)],axis=1)\n",
    "    submission.columns = ['ID','Target']\n",
    "    submission.to_csv('../data/submissions/submission'+str(submission_number)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(2,y_pred_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
