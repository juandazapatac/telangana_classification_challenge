{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "This notebook searchs to use machine learning techniques to model the studied data in the exploratory_analysis.ipynb notebook. First we install and import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the data collected from the satellite images (See the satellite processing folder) is added to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Train.csv')\n",
    "df_encoded = pd.read_csv('../data/train_encoded.csv')\n",
    "df = pd.concat([df,df_encoded.ndvi,df_encoded.evi,df_encoded.ndwi,df_encoded.gndvi,df_encoded.savi,df_encoded.msavi],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About one thousand farms don't have satellite data associted so all they have for the new data are missing values. These records are dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a short multivariate analysis to see what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ndvi</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ndwi</th>\n",
       "      <th colspan=\"2\" halign=\"left\">gndvi</th>\n",
       "      <th colspan=\"2\" halign=\"left\">savi</th>\n",
       "      <th colspan=\"2\" halign=\"left\">msavi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diseased</th>\n",
       "      <td>0.568699</td>\n",
       "      <td>1.460792</td>\n",
       "      <td>10.042921</td>\n",
       "      <td>2.677730</td>\n",
       "      <td>0.254835</td>\n",
       "      <td>0.694027</td>\n",
       "      <td>0.839677</td>\n",
       "      <td>2.176318</td>\n",
       "      <td>3878.101041</td>\n",
       "      <td>1390.030283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthy</th>\n",
       "      <td>0.682831</td>\n",
       "      <td>1.637722</td>\n",
       "      <td>10.215223</td>\n",
       "      <td>2.771421</td>\n",
       "      <td>0.295578</td>\n",
       "      <td>0.899111</td>\n",
       "      <td>1.015285</td>\n",
       "      <td>2.448178</td>\n",
       "      <td>3845.658390</td>\n",
       "      <td>1505.893835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pests</th>\n",
       "      <td>0.725410</td>\n",
       "      <td>1.800500</td>\n",
       "      <td>10.218539</td>\n",
       "      <td>2.646600</td>\n",
       "      <td>0.257164</td>\n",
       "      <td>0.553859</td>\n",
       "      <td>1.085837</td>\n",
       "      <td>2.700968</td>\n",
       "      <td>3879.532629</td>\n",
       "      <td>1503.934969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stressed</th>\n",
       "      <td>0.912816</td>\n",
       "      <td>2.261620</td>\n",
       "      <td>10.440244</td>\n",
       "      <td>2.919329</td>\n",
       "      <td>0.362572</td>\n",
       "      <td>1.271307</td>\n",
       "      <td>1.345018</td>\n",
       "      <td>3.316586</td>\n",
       "      <td>3763.602500</td>\n",
       "      <td>1556.208114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ndvi                 ndwi               gndvi            \\\n",
       "              mean       std       mean       std      mean       std   \n",
       "category                                                                \n",
       "Diseased  0.568699  1.460792  10.042921  2.677730  0.254835  0.694027   \n",
       "Healthy   0.682831  1.637722  10.215223  2.771421  0.295578  0.899111   \n",
       "Pests     0.725410  1.800500  10.218539  2.646600  0.257164  0.553859   \n",
       "Stressed  0.912816  2.261620  10.440244  2.919329  0.362572  1.271307   \n",
       "\n",
       "              savi                  msavi               \n",
       "              mean       std         mean          std  \n",
       "category                                                \n",
       "Diseased  0.839677  2.176318  3878.101041  1390.030283  \n",
       "Healthy   1.015285  2.448178  3845.658390  1505.893835  \n",
       "Pests     1.085837  2.700968  3879.532629  1503.934969  \n",
       "Stressed  1.345018  3.316586  3763.602500  1556.208114  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_satellite = pd.concat([df.ndvi,df.ndwi,df.gndvi,df.savi,df.msavi,df.category],axis=1)\n",
    "df_satellite_gb = df_satellite.groupby('category')\n",
    "df_satellite_gb.agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the dataset is manipulated in order to keep only those features that may be useful for the intended purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next features are removed from the dataset:\n",
    "- FarmID\n",
    "- State\n",
    "- District\n",
    "- Sub-District\n",
    "- HDate\n",
    "- CNext\n",
    "- ExpYield\n",
    "- geometry\n",
    "- CHeight\n",
    "- evi (Problematic feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['FarmID','State','District','Sub-District','HDate','CNext','ExpYield','geometry','CHeight','evi'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SDate is manipulated to keep only the month data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMonth'] = df['SDate'].map(lambda x:x[-7:-5]).astype(int)\n",
    "df.drop(columns='SDate',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category column is converted to numerical through a fixed encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_encoding = {'Healthy':0,\n",
    "                     'Diseased':1,\n",
    "                     'Pests':2,\n",
    "                     'Stressed':3}\n",
    "\n",
    "df['y'] = df.category.map(category_encoding)\n",
    "df.drop(columns=['category'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical variables are converted to numerical through the label-enconding technique. This is chosen for simplicity but it is important to take into account that this is better suited for ordinal variables which is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder2 = LabelEncoder()\n",
    "label_encoder3 = LabelEncoder()\n",
    "label_encoder4 = LabelEncoder()\n",
    "label_encoder5 = LabelEncoder()\n",
    "label_encoder6 = LabelEncoder()\n",
    "df['crop'] = label_encoder1.fit_transform(df.Crop.values)\n",
    "df['clast'] = label_encoder2.fit_transform(df.CLast.values)\n",
    "df['ctransp'] = label_encoder3.fit_transform(df.CTransp.values)\n",
    "df['irritype'] = label_encoder4.fit_transform(df.IrriType.values)\n",
    "df['irrisource'] = label_encoder5.fit_transform(df.IrriSource.values)\n",
    "df['season'] = label_encoder6.fit_transform(df.Season.values)\n",
    "df.drop(columns=['Crop','CLast','CTransp', 'IrriType','IrriSource','Season'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, numerical variables are scaled as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler()\n",
    "scaler2 = StandardScaler()\n",
    "scaler3 = StandardScaler()\n",
    "scaler4 = StandardScaler()\n",
    "scaler5 = StandardScaler()\n",
    "scaler6 = StandardScaler()\n",
    "scaler7 = StandardScaler()\n",
    "\n",
    "df['crop_covered_area'] = scaler1.fit_transform(pd.DataFrame(df.CropCoveredArea))\n",
    "df['water_cov'] = scaler2.fit_transform(pd.DataFrame(df.WaterCov))\n",
    "df['ndvi'] = scaler3.fit_transform(pd.DataFrame(df.ndvi))\n",
    "df['ndwi'] = scaler4.fit_transform(pd.DataFrame(df.ndwi))\n",
    "df['gndvi'] = scaler5.fit_transform(pd.DataFrame(df.gndvi))\n",
    "df['savi'] = scaler6.fit_transform(pd.DataFrame(df.savi))\n",
    "df['msavi'] = scaler7.fit_transform(pd.DataFrame(df.msavi))\n",
    "\n",
    "\n",
    "df.drop(columns=['CropCoveredArea','WaterCov'],inplace=True)\n",
    "df.sort_index(axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step attemps to prepare the provided test data so that it can be evaluated by the models to be built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/Test.csv')\n",
    "#Satellite data\n",
    "df_test_encoded = pd.read_csv('../data/test_encoded.csv')\n",
    "df_test = pd.concat([df_test,df_test_encoded.ndvi,df_test_encoded.evi,df_test_encoded.ndwi,df_test_encoded.gndvi,\n",
    "                   df_test_encoded.savi,df_test_encoded.msavi],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records in the test data with missing values cannot be just dropped as it was done for the training data as they are must be there so that submissions to the platform are valid.\n",
    "\n",
    "So another approach for missing values must me performed. Missing values are fill with the variable's mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [df_test.ndvi,df_test.evi,df_test.ndwi,df_test.gndvi, df_test.savi,df_test.msavi]:\n",
    "    column.fillna(column.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the rest of required transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used columns\n",
    "df_test.drop(columns = ['FarmID','State','District','Sub-District','HDate','CNext',\n",
    "                      'ExpYield','geometry','CHeight','evi'],inplace=True)\n",
    "# Date to Month\n",
    "df_test['SMonth'] = df_test['SDate'].map(lambda x:x[-7:-5]).astype(int)\n",
    "df_test.drop(columns = 'SDate',inplace = True)\n",
    "# Label Encoding\n",
    "df_test['crop'] = label_encoder1.transform(df_test.Crop.values)\n",
    "df_test['clast'] = label_encoder2.transform(df_test.CLast.values)\n",
    "df_test['ctransp'] = label_encoder3.transform(df_test.CTransp.values)\n",
    "df_test['irritype'] = label_encoder4.transform(df_test.IrriType.values)\n",
    "df_test['irrisource'] = label_encoder5.transform(df_test.IrriSource.values)\n",
    "df_test['season'] = label_encoder6.transform(df_test.Season.values)\n",
    "df_test.drop(columns = ['Crop','CLast','CTransp', 'IrriType','IrriSource','Season'],inplace=True)\n",
    "# Scaling\n",
    "df_test['crop_covered_area'] = scaler1.transform(pd.DataFrame(df_test.CropCoveredArea))\n",
    "df_test['water_cov'] = scaler2.transform(pd.DataFrame(df_test.WaterCov))\n",
    "df_test['ndvi'] = scaler3.fit_transform(pd.DataFrame(df_test.ndvi))\n",
    "df_test['ndwi'] = scaler4.fit_transform(pd.DataFrame(df_test.ndwi))\n",
    "df_test['gndvi'] = scaler5.fit_transform(pd.DataFrame(df_test.gndvi))\n",
    "df_test['savi'] = scaler6.fit_transform(pd.DataFrame(df_test.savi))\n",
    "df_test['msavi'] = scaler7.fit_transform(pd.DataFrame(df_test.msavi))\n",
    "df_test.drop(columns = ['CropCoveredArea','WaterCov'],inplace=True)\n",
    "# Sorting columns\n",
    "df_test.sort_index(axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The next data is used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=df.y\n",
    "X_train=df.drop(columns='y')\n",
    "X_test=df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some cases a more balanced dataset will be used, so an undersampling of the majority class is performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "0    422\n",
      "1    422\n",
      "2    422\n",
      "3    422\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "print(y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the *curse of dimensionality* only three variables are used with this algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted average f1-score for 1 neighbors is 0.69600555973801\n",
      "The weighted average f1-score for 2 neighbors is 0.7326263204638507\n",
      "The weighted average f1-score for 3 neighbors is 0.7378557350508214\n",
      "The weighted average f1-score for 4 neighbors is 0.7315497662425016\n",
      "The weighted average f1-score for 5 neighbors is 0.7304993757802747\n"
     ]
    }
   ],
   "source": [
    "# Only the ndvi, savi and SMonth variables are kept\n",
    "X_train_knn = pd.concat([X_train.ndvi,X_train.savi,X_train.water_cov],axis=1)\n",
    "\n",
    "\n",
    "# For this case, we will divide the original training data\n",
    "X_train_knn,X_test_knn,y_train_knn,y_test_knn = train_test_split(X_train_knn,y_train,test_size=0.2,\n",
    "                                                               random_state=42, shuffle=True)\n",
    "\n",
    "for n in range(1,6):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train_knn,y_train_knn)\n",
    "    y_pred_knn = knn.predict(X_test_knn)\n",
    "    f1_score_knn = f1_score(y_test_knn,y_pred_knn,average=\"weighted\")\n",
    "    print('The weighted average f1-score for',n,'neighbors is',f1_score_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last, it is possible to observe that the best number for N is 3.\n",
    "(Different variable combinations were also tested despite not being shown here).\n",
    "\n",
    "Now we train an algorithm without splitting the training data, and we test it using the actual test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_knn = pd.concat([X_train.ndvi,X_train.savi,X_train.water_cov],axis=1)\n",
    "X_test_knn = pd.concat([X_test.ndvi,X_test.savi,X_test.water_cov],axis=1)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=n)\n",
    "knn.fit(X_train_knn,y_train)\n",
    "y_pred_knn = knn.predict(X_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logistic_regression(X_train,y_train):\n",
    "    model = LogisticRegression(max_iter=10000)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_training = model.predict(X_train)\n",
    "    f1 = f1_score(y_train,y_pred_training,average='weighted')\n",
    "    print('The weighted average f1-score for the training data is',f1)\n",
    "    y_pred=model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted average f1-score for the training data is 0.7456103794694815\n",
      "0    3015\n",
      "3       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr=compute_logistic_regression(X_train,y_train)\n",
    "print(pd.Series(y_pred_lr).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm doesn't work that much. It just assigns class 0 to all records. Let's try to deal with the unbalanced present in our dataset by undersampling the majority class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted average f1-score for the training data is 0.31853981124505937\n",
      "1    973\n",
      "2    844\n",
      "0    667\n",
      "3    532\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr_resampled=compute_logistic_regression(X_train_resampled,y_train_resampled)\n",
    "print(pd.Series(y_pred_lr_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It didn't work neither, as now the metric dropped dramatically. The model has a very large bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After several tests only the ndvi, savi and water_cov variables are kept since they are giving the best results\n",
    "X_train_tree = pd.concat([X_train.ndvi,X_train.savi,X_train.water_cov],axis=1)\n",
    "\n",
    "# For this case, we will divide the original training data\n",
    "X_train_tree,X_test_tree,y_train_tree,y_test_tree = train_test_split(X_train,y_train,test_size=0.2,\n",
    "                                                               random_state=42, shuffle=True)\n",
    "model = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=10)\n",
    "model = model.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "y_pred_tree=model.predict(X_test_tree)\n",
    "\n",
    "# Performance evaluation\n",
    "f1_score_tree = f1_score(y_test_tree, y_pred_tree, average=\"weighted\")  # Weighted average f1-score\n",
    "print(f\"The weighted average f1-score is : {f1_score_tree}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification report :\")\n",
    "print(classification_report(y_test_tree, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "As models in general have been generating a large bias, which indicates very simple models, let's use a boosting method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xgboost(X_train,y_train,n,d,X_test):\n",
    "    xgb_model = xgb.XGBClassifier(eval_metric='mlogloss',n_estimators=n,max_depth=d)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred_training = xgb_model.predict(X_train)\n",
    "    f1 = f1_score(y_train,y_pred_training,average='weighted')\n",
    "    print('the weighted average f1-score in the training set is',f1)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As done for KNeighbors, we do a 80-20 split in the original training data so that we can use this 20 percent as a test data where we will be able to understand the generalization capabilities of the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 50 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7488578693674905\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 50 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7554745937123992\n",
      "and in the test set is 0.742850339187808 \n",
      "\n",
      "n= 50 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7841592965397438\n",
      "and in the test set is 0.7424725747222608 \n",
      "\n",
      "n= 50 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8467043964171623\n",
      "and in the test set is 0.7421933589776176 \n",
      "\n",
      "n= 55 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7488578693674905\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 55 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7572480581044051\n",
      "and in the test set is 0.7427244528091455 \n",
      "\n",
      "n= 55 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7903866592888201\n",
      "and in the test set is 0.742450132514995 \n",
      "\n",
      "n= 55 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8657132638343065\n",
      "and in the test set is 0.7424457357839792 \n",
      "\n",
      "n= 60 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7488578693674905\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 60 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7596087865709604\n",
      "and in the test set is 0.7425985313255251 \n",
      "\n",
      "n= 60 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8008900141293577\n",
      "and in the test set is 0.742450132514995 \n",
      "\n",
      "n= 60 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8800698251019139\n",
      "and in the test set is 0.7425718713591934 \n",
      "\n",
      "n= 65 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7488578693674905\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 65 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7619088536930795\n",
      "and in the test set is 0.7427244528091455 \n",
      "\n",
      "n= 65 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.808955472054199\n",
      "and in the test set is 0.7425761273826128 \n",
      "\n",
      "n= 65 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8925970585976312\n",
      "and in the test set is 0.7423175572262221 \n",
      "\n",
      "n= 70 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7494680589859001\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 70 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7653349311406509\n",
      "and in the test set is 0.7425761273826128 \n",
      "\n",
      "n= 70 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8176035900365977\n",
      "and in the test set is 0.7423241024925596 \n",
      "\n",
      "n= 70 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.9119246069470794\n",
      "and in the test set is 0.742191351208803 \n",
      "\n",
      "n= 75 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7488578693674905\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 75 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7681644690612698\n",
      "and in the test set is 0.7425761273826128 \n",
      "\n",
      "n= 75 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8231319317511301\n",
      "and in the test set is 0.7423241024925596 \n",
      "\n",
      "n= 75 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.9249005843785563\n",
      "and in the test set is 0.742189359502139 \n",
      "\n",
      "n= 80 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7500780671332423\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 80 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7704343470564419\n",
      "and in the test set is 0.7423241024925596 \n",
      "\n",
      "n= 80 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8337873809609894\n",
      "and in the test set is 0.7421980373005906 \n",
      "\n",
      "n= 80 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.9372719042622314\n",
      "and in the test set is 0.7419101439599262 \n",
      "\n",
      "n= 85 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7500740871058666\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 85 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7725145341853866\n",
      "and in the test set is 0.7425761273826128 \n",
      "\n",
      "n= 85 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8453550159466425\n",
      "and in the test set is 0.7420719369243651 \n",
      "\n",
      "n= 85 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.9479063632986134\n",
      "and in the test set is 0.7415290425692563 \n",
      "\n",
      "n= 90 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7506843347128486\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 90 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7757718573253104\n",
      "and in the test set is 0.7425761273826128 \n",
      "\n",
      "n= 90 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8531664142565043\n",
      "and in the test set is 0.7418196305602085 \n",
      "\n",
      "n= 90 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.9563974149142828\n",
      "and in the test set is 0.741046036974697 \n",
      "\n",
      "n= 95 d= 2 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7506839333602283\n",
      "and in the test set is 0.7429761904761906 \n",
      "\n",
      "n= 95 d= 3 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.7779783066093784\n",
      "and in the test set is 0.742450132514995 \n",
      "\n",
      "n= 95 d= 4 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.8614681315687024\n",
      "and in the test set is 0.7415671832821372 \n",
      "\n",
      "n= 95 d= 5 \n",
      "\n",
      "the weighted average f1-score in the training set is 0.9654209716580074\n",
      "and in the test set is 0.7411515124584518 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_split,X_test_split,y_train_split,y_test_split = train_test_split(X_train,y_train,test_size=0.5,\n",
    "                                                               random_state=42, shuffle=True)\n",
    "\n",
    "for n in range(50,100,5):\n",
    "    for d in range(2,6):\n",
    "        print('n=',n,'d=',d,'\\n')\n",
    "        y_pred_split = create_xgboost(X_train_split,y_train_split,n,d,X_test_split)\n",
    "        f1 = f1_score(y_test_split,y_pred_split,average='weighted')\n",
    "        print('and in the test set is',f1,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, XGBoost models show to perform similar on both splits which may be an indicator of good generalization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(submission_name,y_pred):\n",
    "    '''\n",
    "    Creates a file ready to submit to the ZINDI platform\n",
    "    '''\n",
    "    submission = pd.read_csv('../data/Test.csv') # Gets the original test file which has the Farm IDs\n",
    "    decoded_categories = []\n",
    "    for i in y_pred:\n",
    "        if i==0: decoded_categories.append('Healthy')\n",
    "        elif i==1: decoded_categories.append('Diseased')\n",
    "        elif i==2: decoded_categories.append('Pests')\n",
    "        elif i==3: decoded_categories.append('Stressed')\n",
    "    submission = pd.concat([submission.FarmID,pd.Series(decoded_categories)],axis=1)\n",
    "    submission.columns = ['ID','Target']\n",
    "    submission.to_csv('../data/submissions/submission'+submission_name+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission #J2:**\n",
    "Logistic regressor built with all the features present in X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_lr=compute_logistic_regression(X_train,y_train)\n",
    "#create_submission('j2',y_pred_lr_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission #J3**: XGBoost (By default 100 estimators and a depth of 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weighted average f1-score in the training set is 0.9439670747773803\n"
     ]
    }
   ],
   "source": [
    "y_pred_j3=create_xgboost(X_train,y_train,X_test)\n",
    "create_submission('j3',y_pred_j3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission #J4**: XGBoost, with 3 estimators and a depth of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weighted average f1-score in the training set is 0.746523058728019\n"
     ]
    }
   ],
   "source": [
    "y_pred_j4=create_xgboost(X_train,y_train,3,4,X_test)\n",
    "create_submission('j4',y_pred_j4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission #J5**: XGBoost, with 100 estimators and a depth of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weighted average f1-score in the training set is 0.8685967027144323\n",
      "0    2999\n",
      "2      16\n",
      "3       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_j5=create_xgboost(X_train,y_train,100,5,X_test)\n",
    "print(pd.Series(y_pred_j5).value_counts())\n",
    "create_submission('j5',y_pred_j5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission #J6**: XGBoost, with 50 estimators and a depth of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weighted average f1-score in the training set is 0.78413519383832\n",
      "0    3006\n",
      "2       9\n",
      "1       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_j6=create_xgboost(X_train,y_train,50,5,X_test)\n",
    "print(pd.Series(y_pred_j6).value_counts())\n",
    "create_submission('j6',y_pred_j6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission #J7**: XGBoost, with 100 estimators and a depth of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weighted average f1-score in the training set is 0.7926450864304826\n",
      "0    3003\n",
      "2       9\n",
      "3       3\n",
      "1       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_j7=create_xgboost(X_train,y_train,100,4,X_test)\n",
    "print(pd.Series(y_pred_j7).value_counts())\n",
    "create_submission('j7',y_pred_j7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission #J8**: XGBoost, with 100 estimators and a depth of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weighted average f1-score in the training set is 0.7561333196455832\n",
      "0    2995\n",
      "2      17\n",
      "1       3\n",
      "3       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_j8=create_xgboost(X_train,y_train,100,3,X_test)\n",
    "print(pd.Series(y_pred_j8).value_counts())\n",
    "create_submission('j8',y_pred_j8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission #J9**: XGBoost, with 75 estimators and a depth of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weighted average f1-score in the training set is 0.773659822526772\n",
      "0    3004\n",
      "2       8\n",
      "3       3\n",
      "1       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_j9=create_xgboost(X_train,y_train,75,4,X_test)\n",
    "print(pd.Series(y_pred_j9).value_counts())\n",
    "create_submission('j9',y_pred_j9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission #J10**: XGBoost, with 150 estimators and a depth of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weighted average f1-score in the training set is 0.8334713610492466\n",
      "0    2993\n",
      "2      16\n",
      "3       4\n",
      "1       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_j10=create_xgboost(X_train,y_train,150,4,X_test)\n",
    "print(pd.Series(y_pred_j10).value_counts())\n",
    "create_submission('j10',y_pred_j10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weighted average f1-score in the training set is 0.8106949789359852\n",
      "0    2996\n",
      "2      16\n",
      "3       3\n",
      "1       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred_j11=create_xgboost(X_train,y_train,125,4,X_test)\n",
    "print(pd.Series(y_pred_j11).value_counts())\n",
    "create_submission('j11',y_pred_j11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
